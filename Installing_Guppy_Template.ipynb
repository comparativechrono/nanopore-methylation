{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/nanopore-methylation/blob/main/Installing_Guppy_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRyLplwKk90e"
      },
      "source": [
        "# Installing Guppy GPU from scratch \n",
        "You can even try it in this notebook on Colab. The very first thing to do is to identify if the GPU allocated to you will actually work! This blog post will tell you if it will: https://gist.github.com/sirselim/13f70ae69f2a512e7d9e1f00f9704f53"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check the GPU available to you"
      ],
      "metadata": {
        "id": "llsnoWKliuiH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FvDkek6DDBhQ",
        "outputId": "1c0b718d-6b6e-4683-a3ec-7a92252503d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()       # this will tell you device number (should be 0 with a single GPU)\n",
        "\n",
        "import torch\n",
        "torch.cuda.get_device_name(0)   # this will tell you the name/model of the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Xkbx1rD6IV",
        "outputId": "10360be7-f7aa-4aba-cf12-72ec9ec8e088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun  1 12:44:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    35W / 250W |   1045MiB / 16280MiB |      3%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# this will give you the full info of your GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr30ptLFwlg2",
        "outputId": "64957bee-ce83-41fc-f5ea-d0bbebf74a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-01 12:44:52--  https://cdn.oxfordnanoportal.com/software/analysis/ont-guppy_6.1.7_linux64.tar.gz\n",
            "Resolving cdn.oxfordnanoportal.com (cdn.oxfordnanoportal.com)... 52.222.158.121, 52.222.158.129, 52.222.158.113, ...\n",
            "Connecting to cdn.oxfordnanoportal.com (cdn.oxfordnanoportal.com)|52.222.158.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1503147580 (1.4G) [application/x-tar]\n",
            "Saving to: ‘ont-guppy_6.1.7_linux64.tar.gz.1’\n",
            "\n",
            "ont-guppy_6.1.7_lin 100%[===================>]   1.40G   166MB/s    in 8.9s    \n",
            "\n",
            "2022-06-01 12:45:02 (161 MB/s) - ‘ont-guppy_6.1.7_linux64.tar.gz.1’ saved [1503147580/1503147580]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://cdn.oxfordnanoportal.com/software/analysis/ont-guppy_6.1.7_linux64.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGn76LJYwwjb"
      },
      "outputs": [],
      "source": [
        "! tar -xf ont-guppy_6.1.7_linux64.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Roy0gM0HlHxy"
      },
      "source": [
        "Make sure you use the version of Guppy that you have installed, by calling it from the directory it is in, or adding it to path. If running on a VM that I have provided the directory structure from the home directory will be as written in the commands here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G614qwxxmL6I"
      },
      "source": [
        "# Basecalling with guppy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQeP_N-KxAyF",
        "outputId": "647e71b9-42e2-4cfb-b7a5-d63d9d0f4a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ": Guppy Basecalling Software, (C) Oxford Nanopore Technologies plc. Version 6.1.7+21b93d1, minimap2 version 2.22-r1101\n",
            "\n",
            "Use of this software is permitted solely under the terms of the end user license agreement (EULA).By running, copying or accessing this software, you are demonstrating your acceptance of the EULA.\n",
            "The EULA may be found in /content/ont-guppy/bin\n",
            "\n",
            "Usage:\n",
            "\n",
            "With config file:\n",
            "  guppy_basecaller -i <input path> -s <save path> -c <config file> [options]\n",
            "With flowcell and kit name:\n",
            "  guppy_basecaller -i <input path> -s <save path> --flowcell <flowcell name>\n",
            "    --kit <kit name>\n",
            "List supported flowcells and kits:\n",
            "  guppy_basecaller --print_workflows\n",
            "\n",
            "Use GPU for basecalling:\n",
            "  guppy_basecaller -i <input path> -s <save path> -c <config file>\n",
            "    --device <cuda device name> [options]\n",
            "\n",
            "Command line parameters:\n",
            "-c [ --config ]\n",
            "\tConfiguration file for application.\n",
            "-d [ --data_path ]\n",
            "\tPath to use for loading any data files the application requires.\n",
            "-x [ --device ]\n",
            "\tSpecify GPU device: 'auto', or 'cuda:<device_id>'.\n",
            "-s [ --save_path ]\n",
            "\tPath to save output files.\n",
            "--ping_url\n",
            "\tURL to send pings to.\n",
            "--trace_domains_config\n",
            "\tConfiguration file containing list of trace domains to include in verbose logging (if enabled)\n",
            "--progress_stats_frequency\n",
            "\tFrequency in seconds in which to report progress statistics, if supplied will replace the default progress display.\n",
            "--ping_segment_duration\n",
            "\tDuration in minutes of each ping segment.\n",
            "-z [ --quiet ]\n",
            "\tQuiet mode. Nothing will be output to STDOUT if this option is set.\n",
            "--verbose_logs\n",
            "\tEnable verbose logs.\n",
            "--disable_pings\n",
            "\tDisable the transmission of telemetry pings.\n",
            "-h [ --help ]\n",
            "\tDisplay the application usage help.\n",
            "-v [ --version ]\n",
            "\tDisplay the application version information.\n",
            "--trace_category_logs\n",
            "\tEnable trace logs - list of strings with the desired names.\n",
            "-r [ --recursive ]\n",
            "\tSearch for input file recursively.\n",
            "-i [ --input_path ]\n",
            "\tPath to input files.\n",
            "--input_file_list\n",
            "\tOptional file containing list of input fast5 files to process from the input_path.\n",
            "-l [ --read_id_list ]\n",
            "\tFile containing list of read ids to filter to.\n",
            "--sample_sheet\n",
            "\tOptional file containing sample sheet.  Used to provide an alias for barcode results.\n",
            "--read_batch_size\n",
            "\tMaximum batch size, in reads, for grouping input files.\n",
            "--nested_output_folder\n",
            "\tIf flagged output FastQ/BAM files will be written to a nested folder structure, based on: protocol_group/sample/protocol/qscore_pass_fail/barcode_arrangement/\n",
            "--barcode_nested_output_folder\n",
            "\tIf flagged output FastQ/BAM files will be written to a nested folder structure, based on: protocol_group/barcode_arrangement/sample/protocol/qscore_pass_fail/\n",
            "--fast5_out\n",
            "\tChoice of whether to do fast5 output.\n",
            "--resume\n",
            "\tResume a previous basecall run using the same output folder.\n",
            "-q [ --records_per_fastq ]\n",
            "\tMaximum number of records per fastq file, 0 means use a single file (per worker, per run id).\n",
            "--bam_methylation_threshold\n",
            "\tThe value below which a predicted methylation probability will not be emitted into a BAM file, expressed as a percentage.\n",
            "--compress_fastq\n",
            "\tCompress fastq output files with gzip.\n",
            "--bam_out\n",
            "\tOutput BAM files.\n",
            "--index\n",
            "\tOutput BAM index file.\n",
            "--moves_out\n",
            "\tReturn move table in output BAM file.\n",
            "--max_queued_reads\n",
            "\tMaximum number of reads in input queue.\n",
            "--trim_threshold\n",
            "\tThreshold above which data will be trimmed (in standard deviations of current level distribution).\n",
            "--trim_min_events\n",
            "\tAdapter trimmer minimum stride intervals after stall that must be seen.\n",
            "--max_search_len\n",
            "\tMaximum number of samples to search through for the stall\n",
            "--override_scaling\n",
            "\tManually provide scaling parameters rather than estimating them from each read.\n",
            "--scaling_med\n",
            "\tMedian current value to use for manual scaling.\n",
            "--scaling_mad\n",
            "\tMedian absolute deviation to use for manual scaling.\n",
            "--trim_strategy\n",
            "\tTrimming strategy to apply: 'dna' or 'rna' (or 'none' to disable trimming)\n",
            "--dmean_win_size\n",
            "\tWindow size for coarse stall event detection\n",
            "--dmean_threshold\n",
            "\tThreshold for coarse stall event detection\n",
            "--jump_threshold\n",
            "\tThreshold level for rna stall detection\n",
            "--pt_scaling\n",
            "\tEnable polyT/adapter max detection for read scaling.\n",
            "--pt_median_offset\n",
            "\tSet polyT median offset for setting read scaling median.\n",
            "--adapter_pt_range_scale\n",
            "\tSet polyT/adapter range scale for setting read scaling median absolute deviation.\n",
            "--pt_required_adapter_drop\n",
            "\tSet minimum required current drop from adapter max to polyT detection.\n",
            "--pt_minimum_read_start_index\n",
            "\tSet minimum index for read start sample required to attempt polyT scaling.\n",
            "--as_model_file\n",
            "\tPath to JSON model file for adapter scaling.\n",
            "--as_gpu_runners_per_device\n",
            "\tNumber of runners per GPU device for adapter scaling.\n",
            "--as_cpu_threads_per_scaler\n",
            "\tNumber of CPU worker threads per adapter scaler.\n",
            "--as_reads_per_runner\n",
            "\tMaximum reads per runner for adapter scaling.\n",
            "--as_num_scalers\n",
            "\tNumber of parallel scalers for adapter scaling.\n",
            "--noisiest_section_scaling_max_size\n",
            "\tThreshold read size in samples under which nosiest-section scaling will be performed.\n",
            "-m [ --model_file ]\n",
            "\tPath to JSON model file.\n",
            "-k [ --kernel_path ]\n",
            "\tPath to GPU kernel files location (only needed if builtin_scripts is false).\n",
            "--builtin_scripts\n",
            "\tWhether to use GPU kernels that were included at compile-time.\n",
            "--chunk_size\n",
            "\tStride intervals per chunk.\n",
            "--chunks_per_runner\n",
            "\tMaximum chunks per runner.\n",
            "--chunks_per_caller\n",
            "\tSoft limit on number of chunks in each caller's queue. New reads will not be queued while this is exceeded.\n",
            "--high_priority_threshold\n",
            "\tNumber of high priority chunks to process for each medium priority chunk.\n",
            "--medium_priority_threshold\n",
            "\tNumber of medium priority chunks to process for each low priority chunk.\n",
            "--overlap\n",
            "\tOverlap between chunks (in stride intervals).\n",
            "--gpu_runners_per_device\n",
            "\tNumber of runners per GPU device.\n",
            "--cpu_threads_per_caller\n",
            "\tNumber of CPU worker threads per basecaller.\n",
            "--num_callers\n",
            "\tNumber of parallel basecallers to create.\n",
            "--num_base_mod_threads\n",
            "\tThe number of threads to use for Remora modified base detection in GPU basecalling mode.\n",
            "--post_out\n",
            "\tReturn full posterior matrix in output fast5 file and/or called read message from server.\n",
            "--stay_penalty\n",
            "\tScaling factor to apply to stay probability calculation during transducer decode.\n",
            "--qscore_offset\n",
            "\tQscore calibration offset.\n",
            "--qscore_scale\n",
            "\tQscore calibration scale factor.\n",
            "--temp_weight\n",
            "\tTemperature adjustment for weight matrix in softmax layer of RNN.\n",
            "--temp_bias\n",
            "\tTemperature adjustment for bias vector in softmax layer of RNN.\n",
            "--beam_cut\n",
            "\tBeam score cutoff for beam search decoding.\n",
            "--beam_width\n",
            "\tBeam score cutoff for beam search decoding.\n",
            "--duplex_window_size_min\n",
            "\tMinimum window size to use for prefix search in duplex decoding.\n",
            "--duplex_window_size_max\n",
            "\tMaximum window size to use for prefix search in duplex decoding.\n",
            "--disable_qscore_filtering\n",
            "\tDisable filtering of reads into PASS/FAIL folders based on min qscore.\n",
            "--min_qscore\n",
            "\tMinimum acceptable qscore for a read to be filtered into the PASS folder.\n",
            "--reverse_sequence\n",
            "\tReverse the called sequence (for RNA sequencing).\n",
            "--u_substitution\n",
            "\tSubstitute 'U' for 'T' in the called sequence (for RNA sequencing).\n",
            "--log_speed_frequency\n",
            "\tHow often to print out basecalling speed.\n",
            "--int8_mode\n",
            "\tEnable quantised int8 mode for kernels which support it.\n",
            "--barcode_kits\n",
            "\tSpace separated list of barcoding kit(s) or expansion kit(s) to detect against. Must be in double quotes.\n",
            "--trim_barcodes\n",
            "\tTrim the barcodes from the sequences in the output files.\n",
            "--trim_adapters\n",
            "\tTrim the adapters from the sequences in the output files.\n",
            "--trim_primers\n",
            "\tTrim the primers from the sequences in the output files.\n",
            "--num_extra_bases_trim\n",
            "\tHow vigorous to be in trimming the barcode. Default is 0 i.e. the length of the detected barcode. A positive integer means extra bases will be trimmed, a negative number is how many fewer bases (less vigorous) will be trimmed.\n",
            "--min_score_barcode_front\n",
            "\tMinimum score to consider a front barcode to be a valid barcode alignment.\n",
            "--min_score_barcode_rear\n",
            "\tMinimum score to consider a rear barcode to be a valid alignment (and min_score_front will then be used for the front only when this is set).\n",
            "--min_score_barcode_mask\n",
            "\tMinimum score for a barcode context to be considered a valid alignment.\n",
            "--min_score_adapter\n",
            "\tMinimum score for an adapter to be considered a valid alignment.\n",
            "--min_score_primer\n",
            "\tMinimum score for a primer to be considered to be a valid alignment.\n",
            "--min_score_adapter_mid\n",
            "\tMinimum score for a mid-strand adapter to be considered a valid alignment.\n",
            "--min_score_barcode_mid\n",
            "\tMinimum score for a barcode to be detected in the middle of a read.\n",
            "--front_window_size\n",
            "\tWindow size for the beginning barcode.\n",
            "--rear_window_size\n",
            "\tWindow size for the ending barcode.\n",
            "--require_barcodes_both_ends\n",
            "\tReads will only be classified if there is a barcode above the min_score at both ends of the read.\n",
            "--allow_inferior_barcodes\n",
            "\tReads will still be classified even if both the barcodes at the front and rear (if applicable) were not the best scoring barcodes above the min_score.\n",
            "--detect_barcodes\n",
            "\tDetect barcode sequences at the front and rear of the read.\n",
            "--detect_adapter\n",
            "\tDetect adapter sequences at the front and rear of the read.\n",
            "--detect_primer\n",
            "\tDetect primer sequences at the front and rear of the read.\n",
            "--detect_mid_strand_barcodes\n",
            "\tSearch for barcodes through the entire length of the read.\n",
            "--detect_mid_strand_adapter\n",
            "\tDetect adapter sequences within reads.\n",
            "--num_barcoding_buffers\n",
            "\tNumber of GPU memory buffers to allocate to perform barcoding into. Controls level of parallelism on GPU for barcoding.\n",
            "--num_mid_barcoding_buffers\n",
            "\tNumber of GPU memory buffers to allocate to perform barcoding into. Controls level of parallelism on GPU for mid barcoding.\n",
            "--num_barcoding_threads\n",
            "\tNumber of worker threads to use for barcoding.\n",
            "--num_reads_per_barcoding_buffer\n",
            "\tThe maximum number of reads to process at once in each barcoding buffer.\n",
            "--lamp_kit\n",
            "\tLAMP barcoding kit to perform LAMP detection against.\n",
            "--min_score_lamp\n",
            "\tMinimum score for a LAMP barcode to be classified.\n",
            "--min_score_lamp_mask\n",
            "\tMinimum score for a LAMP barcode mask context to be classified.\n",
            "--min_score_lamp_target\n",
            "\tMinimum score for a LAMP target to be classified.\n",
            "--min_length_lamp_context\n",
            "\tMinimum align length for a LAMP barcode mask context to be classified.\n",
            "--min_length_lamp_target\n",
            "\tMinimum align length for a LAMP target to be classified.\n",
            "--additional_lamp_context_bases\n",
            "\tNumber of bases from a lamp FIP barcode context to append to the front and read of the FIP barcode before performing matching. Default is 2.\n",
            "--num_read_splitting_buffers\n",
            "\tNumber of GPU memory buffers to allocate to perform read splitting. Controls level of parallelism on GPU for read splitting using mid adapter detection.\n",
            "--num_read_splitting_threads\n",
            "\tNumber of worker threads to use for read splitting.\n",
            "--min_score_read_splitting\n",
            "\tMinimum alignment score for the mid adapter on which to split the read.\n",
            "--do_read_splitting\n",
            "\tPerform read splitting based on mid-strand adapter detection.\n",
            "--max_read_split_depth\n",
            "\tThe maximum number of iterations of read splitting that should be performed.\n",
            "--calib_reference\n",
            "\tReference FASTA file containing calibration strand.\n",
            "--calib_detect\n",
            "\tEnable calibration strand detection and filtering.\n",
            "-a [ --align_ref ]\n",
            "\tReference FASTA or index file.\n",
            "--bed_file\n",
            "\tPath to .bed file containing areas of interest in reference genome.\n",
            "--align_type\n",
            "\tSpecify whether you want full or coarse alignment. Valid values are (auto/full/coarse).\n",
            "--num_alignment_threads\n",
            "\tNumber of worker threads to use for alignment.\n",
            "--print_workflows\n",
            "\tOutput available workflows.\n",
            "--flowcell\n",
            "\tFlowcell to find a configuration for.\n",
            "--kit\n",
            "\tKit to find a configuration for.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! ont-guppy/bin/guppy_basecaller --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2xxOdfblX3v"
      },
      "source": [
        "To pull in a single file from the internet to analyse use wget, here I have put an example fast5 file from our nanopore sequencing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606dMDiNHkAE",
        "outputId": "7e8f7f38-d9e4-4039-80d6-bc89b12ad85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-01 12:45:30--  https://www.dropbox.com/s/ps8prbs4ay1ilni/FAT50823_skip_d652af8d_0.fast5?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.67.18, 2620:100:6023:18::a27d:4312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.67.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/ps8prbs4ay1ilni/FAT50823_skip_d652af8d_0.fast5 [following]\n",
            "--2022-06-01 12:45:30--  https://www.dropbox.com/s/dl/ps8prbs4ay1ilni/FAT50823_skip_d652af8d_0.fast5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc24319d596391474691f67bba16.dl.dropboxusercontent.com/cd/0/get/BmbnKHl0dhK-b0O_RnkqEED8GWLowS0Vgg_W4ECFXoB-M5eEfdnhWjSc1-YsGnaiVOGLGrcEA2R7z4quB8A34gTlfW_T3oWxsNMEvmYUDjGgh-EWMiIbROOVqqkJ8l_6wO9peLM6DBOfNlRivfSoBo7MdQtV70KrxyO_-1-IZ9UBr3J9JVmGZAjZZEhIyCuEhmA/file?dl=1# [following]\n",
            "--2022-06-01 12:45:31--  https://uc24319d596391474691f67bba16.dl.dropboxusercontent.com/cd/0/get/BmbnKHl0dhK-b0O_RnkqEED8GWLowS0Vgg_W4ECFXoB-M5eEfdnhWjSc1-YsGnaiVOGLGrcEA2R7z4quB8A34gTlfW_T3oWxsNMEvmYUDjGgh-EWMiIbROOVqqkJ8l_6wO9peLM6DBOfNlRivfSoBo7MdQtV70KrxyO_-1-IZ9UBr3J9JVmGZAjZZEhIyCuEhmA/file?dl=1\n",
            "Resolving uc24319d596391474691f67bba16.dl.dropboxusercontent.com (uc24319d596391474691f67bba16.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6023:15::a27d:430f\n",
            "Connecting to uc24319d596391474691f67bba16.dl.dropboxusercontent.com (uc24319d596391474691f67bba16.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 236699313 (226M) [application/binary]\n",
            "Saving to: ‘FAT50823_skip_d652af8d_0.fast5’\n",
            "\n",
            "FAT50823_skip_d652a 100%[===================>] 225.73M  22.7MB/s    in 10s     \n",
            "\n",
            "2022-06-01 12:45:42 (22.5 MB/s) - ‘FAT50823_skip_d652af8d_0.fast5’ saved [236699313/236699313]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://www.dropbox.com/s/ps8prbs4ay1ilni/FAT50823_skip_d652af8d_0.fast5?dl=1 -O FAT50823_skip_d652af8d_0.fast5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1MwzkwElzPI"
      },
      "source": [
        "See the workflow available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC93mKJdxOf6",
        "outputId": "fd83f3bd-306c-45d8-ff47-381d4bdb9ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘output’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iowcLqZxUsx",
        "outputId": "f1a25890-1a7d-4266-9f68-c7f92bbab896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-01 12:45:42--  http://ftp.ensembl.org/pub/release-106/fasta/danio_rerio/dna/Danio_rerio.GRCz11.dna.primary_assembly.fa.gz\n",
            "Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.139\n",
            "Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 410230731 (391M) [application/x-gzip]\n",
            "Saving to: ‘Danio_rerio.GRCz11.dna.primary_assembly.fa.gz’\n",
            "\n",
            "Danio_rerio.GRCz11. 100%[===================>] 391.23M  10.9MB/s    in 37s     \n",
            "\n",
            "2022-06-01 12:46:19 (10.5 MB/s) - ‘Danio_rerio.GRCz11.dna.primary_assembly.fa.gz’ saved [410230731/410230731]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget http://ftp.ensembl.org/pub/release-106/fasta/danio_rerio/dna/Danio_rerio.GRCz11.dna.primary_assembly.fa.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0cIJ-1RxW7U",
        "outputId": "880b47c3-53f4-4092-f3f4-fc986d325c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gzip: Danio_rerio.GRCz11.dna.primary_assembly.fa already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ],
      "source": [
        "! gunzip Danio_rerio.GRCz11.dna.primary_assembly.fa.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9PEcpLl2xl"
      },
      "source": [
        "Run a basecalling algorithm - you need to specify the input directory, the output path, and the configuration file for the basecalling algorithm. \n",
        "\n",
        "Note that we want to use a GPU, to do the mapping and basecalling very quickly. This is specified in the options in the command below.\n",
        "\n",
        "Additionally, we want to do mapping and basecalling together - so we here specify that we want bam files and the reference genome to use.\n",
        "\n",
        "Ensure you check you understand what each of the options does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HezZg5r5XY",
        "outputId": "a9085916-f9d6-4c7b-ab1a-2eef0688943a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONT Guppy basecalling software version 6.1.7+21b93d1, minimap2 version 2.22-r1101\n",
            "config file:        /content/ont-guppy/data/dna_r9.4.1_450bps_modbases_5hmc_5mc_cg_hac.cfg\n",
            "model file:         /content/ont-guppy/data/template_r9.4.1_450bps_hac.jsn\n",
            "input path:         ./\n",
            "save path:          /output\n",
            "chunk size:         2000\n",
            "chunks per runner:  256\n",
            "minimum qscore:     9\n",
            "records per file:   4000\n",
            "num basecallers:    4\n",
            "gpu device:         cuda:0\n",
            "kernel path:        \n",
            "runners per device: 16\n",
            "\n",
            "alignment file:     Danio_rerio.GRCz11.dna.primary_assembly.fa\n",
            "alignment type:     auto\n",
            "\n",
            "Use of this software is permitted solely under the terms of the end user license agreement (EULA).By running, copying or accessing this software, you are demonstrating your acceptance of the EULA.\n",
            "The EULA may be found in /content/ont-guppy/bin\n",
            "tcmalloc: large alloc 1073741824 bytes == 0xc9496000 @  0x7f87ecbb82a4 0xbaf5e7 0xba1d7f 0xba708d 0x7f87eaada6db 0x7f87ea64f61f\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! ont-guppy/bin/guppy_basecaller -c dna_r9.4.1_450bps_modbases_5hmc_5mc_cg_hac.cfg --bam_out --recursive --gpu_runners_per_device 16 --cpu_threads_per_caller 2 --device cuda:0 --align_ref Danio_rerio.GRCz11.dna.primary_assembly.fa -i ./ --save_path ./output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Installing_Guppy_Template.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}